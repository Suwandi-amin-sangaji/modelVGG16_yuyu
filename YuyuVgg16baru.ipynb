{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyON2lhnM3rHuBdPDyEzr5r2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suwandi-amin-sangaji/modelVGG16_yuyu/blob/main/YuyuVgg16baru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PQgYd2DMZRF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx6skO1gzka3"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, Lambda, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "os.listdir(\"/content/drive/MyDrive/dataset_obat_yuyu\")\n",
        "\n",
        "print(\"Setup Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 64\n",
        "\n",
        "category = ['Ambroxol_Tablet', 'Diapet_Kapsul', 'Flamar_50_Tablet','Folavit_Tablet', 'Laxing_Kapsul', 'Meftormin_Tablet','Omeprazole_Kapsul','Ranitidine_Tablet','Sangobion_Kapsul','Simcobal_Kapsul']\n",
        "def get_train_data(direct):\n",
        "    data = []\n",
        "    for labels in category:\n",
        "        path = os.path.join(direct, labels)\n",
        "        class_num = category.index(labels)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                data.append([new_array, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)"
      ],
      "metadata": {
        "id": "1QI8sDuZgHOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = get_train_data(\"/content/drive/MyDrive/dataset_obat_yuyu\")"
      ],
      "metadata": {
        "id": "XH5ZzQmlgmfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "for feature, label in new_data:\n",
        "    X.append(feature)\n",
        "    y.append(label)\n",
        "    \n",
        "from keras.utils import np_utils\n",
        "y = np_utils.to_categorical(y, num_classes = 10)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X = X.reshape(-1, 64, 64, 3)"
      ],
      "metadata": {
        "id": "pSqQzPqUkfqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "ee2LehMIgtVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_generator = ImageDataGenerator(rescale = 1/255,\n",
        "                                     zoom_range = 0.3,\n",
        "                                     horizontal_flip = True,\n",
        "                                     rotation_range = 30)\n",
        "\n",
        "test_generator = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "train_generator = train_generator.flow(np.array(X_train),\n",
        "                                       y_train,\n",
        "                                       batch_size = 64,\n",
        "                                       shuffle = False)\n",
        "\n",
        "test_generator = test_generator.flow(np.array(X_test),\n",
        "                                     y_test,\n",
        "                                     batch_size = 64,\n",
        "                                     shuffle = False)\n",
        "\n",
        "print(\"Train data shape: \", X_train.shape)\n",
        "print(\"Train labels shape: \", y_train.shape)\n",
        "print(\"Test data shape: \", X_test.shape)\n",
        "print(\"Test labels shape: \", y_test.shape)"
      ],
      "metadata": {
        "id": "dbxMWjCigzxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vg16 = VGG16(input_shape=[IMG_SIZE, IMG_SIZE] + [3], weights=\"imagenet\", include_top=False)\n",
        "\n",
        "for layer in vg16.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(vg16.output)\n",
        "prediction = Dense(len(category), activation=\"softmax\")(x)\n",
        "model = Model(inputs=vg16.input, outputs=prediction)\n",
        "\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")"
      ],
      "metadata": {
        "id": "Bh4Zqki0g25C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install visualkeras"
      ],
      "metadata": {
        "id": "XyumILAnd1YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import visualkeras\n",
        "visualkeras.layered_view(model)"
      ],
      "metadata": {
        "id": "smqXahiudveR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='modelvgg16yuyu.png',show_shapes=True)"
      ],
      "metadata": {
        "id": "roSgXMlQd9XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                                   steps_per_epoch = len(X_train)/64,\n",
        "                                   epochs = 50,\n",
        "                                   shuffle = False,\n",
        "                                   validation_data=test_generator, validation_steps=len(test_generator))"
      ],
      "metadata": {
        "id": "6xs4iMUEhuhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "VB8FNAzKl5Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "\n",
        "plt.plot(epochs, accuracy, \"b\", label=\"trainning accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"r\", label=\"validation accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss, \"b\", label=\"trainning loss\")\n",
        "plt.plot(epochs, val_loss, \"r\", label=\"validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WjhC2Opul9v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "output_class = ['Ambroxol_Tablet', 'Diapet_Kapsul', 'Flamar_50_Tablet','Folavit_Tablet', 'Laxing_Kapsul', 'Meftormin_Tablet','Omeprazole_Kapsul','Ranitidine_Tablet','Sangobion_Kapsul','Simcobal_Kapsul']\n",
        "def obat(new_image):\n",
        "  test_image = image.load_img(new_image, target_size = (64,64))\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(test_image)\n",
        "  plt.show()\n",
        " \n",
        "  test_image = image.img_to_array(test_image) / 255\n",
        "  test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "  predicted_array = model.predict(test_image)\n",
        "  predicted_value = output_class[np.argmax(predicted_array)]\n",
        "  predicted_accuracy = round(np.max(predicted_array) * 100, 2)\n",
        "\n",
        "  print(\"Obat is \", predicted_value, \" with \", predicted_accuracy, \" % accuracy\")"
      ],
      "metadata": {
        "id": "hQUj5khZvsvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obat('/content/drive/MyDrive/dataset_obat_yuyu/Ambroxol_Tablet/IMG_5408.jpg')"
      ],
      "metadata": {
        "id": "eykQ46qev2t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "model.save('//content/drive/MyDrive/dataset_obat_yuyu/yuyumodel.h5')"
      ],
      "metadata": {
        "id": "yxJDsYWfw_6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_generator)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "pO3RvqtCw4iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "OA1EGetQmRez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=category))\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=category, output_dict=True)\n",
        "\n",
        "# Print the report with a nice formatting\n",
        "print(\"{:<20} {:<10} {:<10} {:<10} {:<10}\".format(\"\", \"precision\", \"recall\", \"f1-score\", \"support\"))\n",
        "for key in report.keys():\n",
        "    if key in category:\n",
        "        values = report[key]\n",
        "        print(\"{:<20} {:<10.2f} {:<10.2f} {:<10.2f} {:<10}\".format(key, values['precision'], values['recall'], values['f1-score'], values['support']))\n",
        "print(\"\\nAccuracy: {:.2f}\".format(accuracy_score(np.argmax(y_test, axis=1), y_pred)))\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
        "\n",
        "# Create a heatmap for the confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False, ax=ax, xticklabels=category, yticklabels=category)\n",
        "ax.set_xlabel('Predicted Labels')\n",
        "ax.set_ylabel('True Labels')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "En_DfD2VmSUN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}